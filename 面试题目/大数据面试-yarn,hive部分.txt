Yarn的集群架构和工作原理
ResourceManager负责整个系统的资源管理和分配，ApplicationMaster负责单个应用程序的的管理。
1) ResourceManager：
RM是一个全局的资源管理器，负责整个系统的资源管理和分配.
调度器根据容量、队列等限制条件，将系统中的资源分配给正在运行的应用程序，在保证容量、公平性和服务等级的前提下，优化集群资源利用率，让所有的资源都被充分利用应用程序管理器负责管理整个系统中的所有的应用程序，包括应用程序的提交、与调度器协商资源以启动ApplicationMaster、监控ApplicationMaster运行状态并在失败时重启它。
2) ApplicationMaster：
用户提交的一个应用程序会对应于一个ApplicationMaster
a.与RM调度器协商以获得资源，资源以Container表示。
b.将得到的任务进一步分配给内部的任务。
c.与NM通信以启动/停止任务。
d.监控所有的内部任务状态，并在任务运行失败的时候重新为任务申请资源以重启任务。、
3) NodeManager：
NodeManager是每个节点上的资源和任务管理器，一方面，它会定期地向RM汇报本节点上的资源使用情况和各个Container的运行状态；另一方面，他接收并处理来自AM的Container启动和停止请求。
4) Container：
Container是YARN中的资源抽象，封装了各种资源。一个应用程序会分配一个Container，这个应用程序只能使用这个Container中描述的资源。

yarn 的任务提交流程是怎样的？
当jobclient向YARN提交一个应用程序后，YARN将分两个阶段运行这个应用程序：一是启动ApplicationMaster;第二个阶段是由ApplicationMaster创建应用程序，为它申请资源，监控运行直到结束。
具体步骤如下:
1) 用户向YARN提交一个应用程序，并指定ApplicationMaster程序、启动ApplicationMaster的命令、用户程序。
2) RM为这个应用程序分配第一个Container，并与之对应的NM通讯，要求它在这个Container中启动应用程序ApplicationMaster
3) ApplicationMaster向RM注册，然后拆分为内部各个子任务，为各个内部任务申请资源，并监控这些任务的运行，直到结束。
4) AM采用轮询的方式向RM申请和领取资源。
5) RM为AM分配资源，以Container形式返回
6) AM申请到资源后，便与之对应的NM通讯，要求NM启动任务。
7) NodeManager为任务设置好运行环境，将任务启动命令写到一个脚本中，并通过运行这个脚本启动任务
8) 各个任务向AM汇报自己的状态和进度，以便当任务失败时可以重启任务。
9) 应用程序完成后，ApplicationMaster向ResourceManager注销并关闭自己

yarn 的资源调度三种模型了解吗？
在Yarn中有三种调度器可以选择：FIFO Scheduler ，Capacity Scheduler，Fair Scheduler
apache版本的hadoop默认使用的是capacity scheduler调度方式。CDH版本的默认使用的是fair scheduler调度方式
FIFO Scheduler（先进先出）：
一个先进先出队列。
Capacity Scheduler（容量调度器）：
对于Capacity调度器，有专门的队列用来运行不同任务。每个队列可配置一定的资源量，每个队列采用FIFO调度策略。

Fair Scheduler（公平调度器）：
在Fair调度器中，Fair调度器会为所有运行的job动态的调整系统资源。
比如：当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。直到所有可用资源都被分配完，并不再分配了。

Hive：由 Facebook 开源用于解决海量结构化日志的数据统计工具。
Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并
提供类 SQL 查询功能。
Hive 本质：将 HQL 转化成 MapReduce 程序！

（1）Hive 处理的数据存储在 HDFS
（2）Hive 分析数据底层的实现是 MapReduce
（3）执行程序运行在 Yarn 上

二、Hive的优缺点
优点
1）操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）。
2）避免了去写 MapReduce，减少开发人员的学习成本。
3）Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。
4）Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。
5）Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

缺点
1）Hive 的 HQL 表达能力有限
（1）迭代式算法无法表达
（2）数据挖掘方面不擅长，由于 MapReduce 数据处理流程的限制，效率更高的算法却无法实现。
2）Hive 的效率比较低
（1）Hive 自动生成的 MapReduce 作业，通常情况下不够智能化
（2）Hive 调优比较困难，粒度较粗

Hive 内部表和外部表的区别
未被external修饰的是内部表（managed table），被external修饰的为外部表（external table）
区别：
1) 内部表数据由Hive自身管理，外部表数据由HDFS管理；
2) 内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse），外部表数据的存储位置由自己制定（如果没有位置，Hive将在HDFS上的/user/hive/warehouse文件夹下以外部表的表名创建一个文件夹，并将属于这个表的数据存放在这里）；
3) 删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除；

hive 有索引吗？
Hive支持索引，但是Hive的索引与关系型数据库中的索引并不相同，比如，Hive不支持主键或者外键。
Hive索引可以建立在表中的某些列上，以提升一些操作的效率，例如减少MapReduce任务中需要读取的数据块的数量。

Hive索引的机制：
hive在指定列上建立索引，会产生一张索引表（Hive的一张物理表），里面的字段包括，索引列的值、该值对应的HDFS文件路径、该值在文件中的偏移量;
因为索引是用空间换时间，索引列的取值过多会导致索引表过大。

运维如何对hive进行调度？
将hive的sql定义在脚本当中
使用azkaban或者oozie进行任务的调度
监控任务调度页面

ORC、Parquet等列式存储的优点？
ORC和Parquet都是高性能的存储方式，这两种存储格式总会带来存储和性能上的提升

为什么要对数据仓库分层？
用空间换时间，通过大量的预处理来提升应用系统的用户体验（效率），因此数据仓库会存在大量冗余的数据。
如果不分层的话，如果源业务系统的业务规则发生变化将会影响整个数据清洗过程，工作量巨大。
通过数据分层管理可以简化数据清洗的过程，因为把原来一步的工作分到了多个步骤去完成，相当于把一个复杂的工作拆成了多个简单的工作。每一层的处理逻辑都相对简单和容易理解，这样比较容易保证每一个步骤的正确性，当数据发生错误的时候，只需要局部调整某个步骤。

sort by 和 order by 的区别？
order by 会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序），会导致当输入规模较大时，需要较长的计算时间。
sort by不是全局排序，其在数据进入reducer前完成排序.
因此，如果用sort by进行排序，并且设置mapred.reduce.tasks>1， 则sort by只保证每个reducer的输出有序，不保证全局有序。

Hive小文件过多怎么解决？
使用 hive 自带的 concatenate 命令，自动合并小文件。使用hadoop的archive将小文件归档

分区表
分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。
1）引入分区表（需要根据日期对日志进行管理, 通过部门信息模拟）
dept_20200401.log
dept_20200402.log
dept_20200403.log

2）创建分区表语法
hive (default)> create table dept_partition(
deptno int, dname string, loc string)
partitioned by (day string)
row format delimited fields terminated by '\t';

3）加载数据到分区表中
（1）
数据准备
dept_20200401.log
10 ACCOUNTING 1700
20 RESEARCH 1800

dept_20200402.log
30 SALES 1900
40 OPERATIONS 1700

dept_20200403.log
50 TEST 2000
60 DEV 1900

2）加载数据
hive (default)> load data local inpath
'/opt/module/hive/datas/dept_20200401.log' into table dept_partition partition(day='20200401');

hive(default)>load data local inpath
'/opt/module/hive/datas/dept_20200402.log' into table dept_partition partition(day='20200402');

hive (default)> load data local inpath
'/opt/module/hive/datas/dept_20200403.log' into table dept_partition partition(day='20200403');
注意：分区表加载数据时，必须指定分区

窗口函数（开窗函数）但是效率比group by 低
OVER()：指定分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变而变化

按需求查询数据
（1）查询在 2017 年 4 月份购买过的顾客及总人数
select name,count(*) over () from business
where substring(orderdate,0,7) = '2017-04' group by name;

（2）查询顾客的购买明细及月购买总额
select name,orderdate,cost,sum(cost) over(partition by month(orderdate)) from business;

（3）将每个顾客的 cost 按照日期进行累加
select name,orderdate,cost, sum(cost) over(partition by name order by orderdate) from business;

（4）查看顾客上次的购买时间
select name,orderdate,lag(orderdate,1) over(partition by name order by orderdate) from business;

（5）查询前 20%时间的订单信息
select * from (select name,orderdate,cost, ntile(5) over(order by orderdate) sorted from business) t
where sorted = 1;

Rank
1）函数说明 也是在over（）中使用的
RANK() 排序相同时会重复，总数不会变
DENSE_RANK() 排序相同时会重复，总数会减少
ROW_NUMBER() 会根据顺序计算

select name,
subject,
score,
rank() over(partition by subject order by score desc) rp,
dense_rank() over(partition by subject order by score desc) drp,
row_number() over(partition by subject order by score desc) rmp
from score;

每门学科前三名
select name,subject,score from (select *,rank() over(partition by subject order by score desc) rk  from score) t1 where rk <=3 ;

hive优化有哪些？
数据存储及压缩。
通过调参优化。
设置map、reduce的参数；
有效地减小数据集将大表拆分成子表；结合使用外部表和分区表。
SQL优化
大表对大表：尽量减少数据集，可以通过分区表，避免扫描全表或者全字段；
大表对小表：设置自动识别小表，将小表放入内存中去执行。